{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import copy\n",
    "import os\n",
    "from bisect import bisect_left\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import enum\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.model import Model\n",
    "from cleverhans.picklable_model import MLP, Conv2D, ReLU, Flatten, Linear, Softmax\n",
    "from cleverhans.train import train\n",
    "from cleverhans.utils_tf import batch_eval, model_eval\n",
    "from cleverhans import serial\n",
    "from pathlib import Path\n",
    "\n",
    "from dknn import DkNNModel, get_tensorflow_session, make_basic_picklable_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = sys.argv[:1]\n",
    "FLAGS = tf.app.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_integer(\n",
    "    'number_bits',\n",
    "    17,\n",
    "    'number of hash bits used by LSH Index'\n",
    "  )\n",
    "tf.flags.DEFINE_float(\n",
    "    'tensorflow_gpu_memory_fraction',\n",
    "    0.25,\n",
    "    'amount of the GPU memory to allocate for a tensorflow Session'\n",
    "  )\n",
    "tf.flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
    "tf.flags.DEFINE_integer('batch_size', 500, 'Size of training batches')\n",
    "tf.flags.DEFINE_float('lr', 0.001, 'Learning rate for training')\n",
    "\n",
    "tf.flags.DEFINE_integer(\n",
    "      'nb_cali', 750, 'Number of calibration points for the DkNN')\n",
    "tf.flags.DEFINE_integer(\n",
    "      'neighbors', 75, 'Number of neighbors per layer for the DkNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST(train_start=0, train_end=10000, test_start=0, test_end=1000)\n",
    "x_train, y_train = mnist.get_set('train')\n",
    "x_test, y_test = mnist.get_set('test')\n",
    "\n",
    "# Use Image Parameters.\n",
    "img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "nb_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/dknn_geod/src/dknn.py:225: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/dknn_geod/src/dknn.py:227: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/dknn_geod/src/dknn.py:228: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/picklable_model.py:251: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/picklable_model.py:186: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/train.py:117: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/compat.py:124: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "num_devices:  1\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/train.py:159: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/utils_tf.py:60: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/utils_tf.py:63: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/utils_tf.py:511: UserWarning: No GPUS, running on CPU\n",
      "  warnings.warn(\"No GPUS, running on CPU\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zekrom/CMU/Fall2019/10715 - Advanced Introduction to Machine Learning/Project/venv/lib/python3.5/site-packages/cleverhans/utils_tf.py:72: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2019-10-29 16:15:28,553 cleverhans] Epoch 0 took 16.651572942733765 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on test examples: 0.8890\n"
     ]
    }
   ],
   "source": [
    "with get_tensorflow_session() as sess:\n",
    "    with tf.variable_scope('dknn'):\n",
    "        # Define input TF placeholder.\n",
    "        x = tf.placeholder(tf.float32, shape=(\n",
    "          None, img_rows, img_cols, nchannels))\n",
    "        y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "\n",
    "        # Define a model.\n",
    "        model = make_basic_picklable_cnn()\n",
    "        preds = model.get_logits(x)\n",
    "        loss = CrossEntropy(model, smoothing=0.)\n",
    "\n",
    "        # Define the test set accuracy evaluation.\n",
    "        def evaluate():\n",
    "            acc = model_eval(sess, x, y, preds, x_test, y_test,\n",
    "                             args={'batch_size': FLAGS.batch_size})\n",
    "            print('Test accuracy on test examples: %0.4f' % acc)\n",
    "\n",
    "        # Train the model\n",
    "        train_params = {'nb_epochs': FLAGS.nb_epochs,\n",
    "                      'batch_size': FLAGS.batch_size, 'learning_rate': FLAGS.lr}\n",
    "\n",
    "        data_filepath = \"model.joblib\"\n",
    "        path = Path(data_filepath)\n",
    "\n",
    "        if path.is_file():\n",
    "            model = serial.load(data_filepath)\n",
    "        else:\n",
    "            train(sess, loss, x_train, y_train, evaluate=evaluate,\n",
    "              args=train_params, var_list=model.get_params())\n",
    "            serial.save(\"model.joblib\", model)\n",
    "\n",
    "          # Define callable that returns a dictionary of all activations for a dataset\n",
    "        def get_activations(data):\n",
    "            data_activations = {}\n",
    "            for layer in layers:\n",
    "                layer_sym = tf.layers.flatten(model.get_layer(x, layer))\n",
    "                data_activations[layer] = batch_eval(sess, [x], [layer_sym], [data],\n",
    "                                                   args={'batch_size': FLAGS.batch_size})[0]\n",
    "            return data_activations\n",
    "\n",
    "        # Use a holdout of the test set to simulate calibration data for the DkNN.\n",
    "        train_data = x_train\n",
    "        train_labels = np.argmax(y_train, axis=1)\n",
    "        cali_data = x_test[:FLAGS.nb_cali]\n",
    "        y_cali = y_test[:FLAGS.nb_cali]\n",
    "        cali_labels = np.argmax(y_cali, axis=1)\n",
    "        test_data = x_test[FLAGS.nb_cali:]\n",
    "        y_test = y_test[FLAGS.nb_cali:]\n",
    "\n",
    "        # Extract representations for the training and calibration data at each layer of interest to the DkNN.\n",
    "        layers = ['ReLU1', 'ReLU3', 'ReLU5', 'logits']\n",
    "\n",
    "        # Wrap the model into a DkNNModel\n",
    "        dknn = DkNNModel(\n",
    "        FLAGS.neighbors,\n",
    "        layers,\n",
    "        get_activations,\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        nb_classes,\n",
    "        scope='dknn'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_kernel import euclidean_kernel, hard_geodesics_euclidean_kernel\n",
    "from utils_visualization import plot_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hola_x = x_train[0:10000].reshape((10000, 28*28))\n",
    "hola_y = train_labels[0:10000]\n",
    "hola_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_matrix = euclidean_kernel(hola_x)\n",
    "max_distance = np.max(euclidean_matrix)+1\n",
    "euclidean_matrix[euclidean_matrix == 0]=max_distance\n",
    "plot_kernel(euclidean_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesic_euclidean_matrix = hard_geodesics_euclidean_kernel(hola_x, 5)\n",
    "max_distance = np.max(geodesic_euclidean_matrix)+1\n",
    "geodesic_euclidean_matrix[geodesic_euclidean_matrix == 0]=max_distance\n",
    "plot_kernel(geodesic_euclidean_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1,20)\n",
    "same_class_euclidean = np.zeros(len(ks))\n",
    "same_class_geodesic = np.zeros(len(ks))\n",
    "for j,k in enumerate(ks):\n",
    "    acum_euc = 0\n",
    "    acum_geo = 0\n",
    "    for i in range(10000):\n",
    "        euclidean_neighbors_idx = np.argpartition(euclidean_matrix[i,:],k)[:k]\n",
    "        acum_euc += np.mean(hola_y[i]==hola_y[euclidean_neighbors_idx])\n",
    "\n",
    "        geodesic_neighbors_idx = np.argpartition(geodesic_euclidean_matrix[i,:],k)[:k]\n",
    "        acum_geo += np.mean(hola_y[i]==hola_y[geodesic_neighbors_idx])\n",
    "    same_class_euclidean[j] = acum_euc/10000\n",
    "    same_class_geodesic[j] = acum_geo/10000\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,20),same_class_euclidean)\n",
    "plt.plot(range(1,20),same_class_geodesic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_path = '../results/geodesic_matrices_1000_5.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(matrix_path, 'rb') as f:\n",
    "    hola = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
